{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Data Clustering Notebook\n",
    "In this notebook, we are interested in performing clustering to produce the top K words for each cluster.\n",
    "\n",
    "Logic\n",
    "1. Read the Review.csv file and convert to Pandas dataframe\n",
    "2. For each review, split into sentences\n",
    "3. Do preprocessing on each of the sentences\n",
    "  - Convert to lowercase\n",
    "  - Remove weird symbols (Regex patterns)\n",
    "  - Stopwords\n",
    "  - Stemming\n",
    "4. Compute TFIDF matrix using vectorizer for each of the sentences\n",
    "5. Cluster the sentences (K-means VS Hierarchial clustering)\n",
    "6. Obtain top 10 words to categorize clusters (Price/Quality/Ambience etc)\n",
    "7. Publish results via Dashboard on Tableau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading Data\n",
    "We first have to read the Yelp data. This data is in the csv file: \"Review.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BusinessId</th>\n",
       "      <th>CoolCount</th>\n",
       "      <th>FunnyCount</th>\n",
       "      <th>NotRecommended</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Text</th>\n",
       "      <th>UsefulCount</th>\n",
       "      <th>UserId</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>long-beach-seafood-singapore</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>Been coming here for more than a decade. Long ...</td>\n",
       "      <td>1</td>\n",
       "      <td>mMjxhRn4h0LD1_jI3RT4cQ</td>\n",
       "      <td>ENx8ZXpulmX5_AfCOp_U3A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>long-beach-seafood-singapore</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>I've been coming here with my boyfriend to onl...</td>\n",
       "      <td>4</td>\n",
       "      <td>tAr3zFVXoM1K2PrbyCdcTA</td>\n",
       "      <td>Tjd32RIUDeOJrYpJ9J6_GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long-beach-seafood-singapore</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>MUST GO! Your life isn't complete without goin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1-5YghuD_7sLuD01f6hrJw</td>\n",
       "      <td>wYuRHgUSBTm6D8B-HrSpNg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>long-beach-seafood-singapore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Excellent service, our waiter was always aroun...</td>\n",
       "      <td>0</td>\n",
       "      <td>ZAaT3T_Yd1re0Nt_MOW7AA</td>\n",
       "      <td>lisryzBzdpf4KNXfx6-3Fg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>long-beach-seafood-singapore</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>Try the Chilli crab. Its gravy was on the swee...</td>\n",
       "      <td>1</td>\n",
       "      <td>oRMf6hs2lgU3bIr_fF_5IA</td>\n",
       "      <td>thceOS2dozAixh8Qu09gOg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     BusinessId  CoolCount  FunnyCount  NotRecommended  \\\n",
       "0  long-beach-seafood-singapore          1           0           False   \n",
       "1  long-beach-seafood-singapore          3           0           False   \n",
       "2  long-beach-seafood-singapore          2           1           False   \n",
       "3  long-beach-seafood-singapore          0           0           False   \n",
       "4  long-beach-seafood-singapore          0           0           False   \n",
       "\n",
       "   Rating                                               Text  UsefulCount  \\\n",
       "0       5  Been coming here for more than a decade. Long ...            1   \n",
       "1       5  I've been coming here with my boyfriend to onl...            4   \n",
       "2       5  MUST GO! Your life isn't complete without goin...            1   \n",
       "3       3  Excellent service, our waiter was always aroun...            0   \n",
       "4       4  Try the Chilli crab. Its gravy was on the swee...            1   \n",
       "\n",
       "                   UserId                     _id  \n",
       "0  mMjxhRn4h0LD1_jI3RT4cQ  ENx8ZXpulmX5_AfCOp_U3A  \n",
       "1  tAr3zFVXoM1K2PrbyCdcTA  Tjd32RIUDeOJrYpJ9J6_GA  \n",
       "2  1-5YghuD_7sLuD01f6hrJw  wYuRHgUSBTm6D8B-HrSpNg  \n",
       "3  ZAaT3T_Yd1re0Nt_MOW7AA  lisryzBzdpf4KNXfx6-3Fg  \n",
       "4  oRMf6hs2lgU3bIr_fF_5IA  thceOS2dozAixh8Qu09gOg  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Import the data file\n",
    "data = pd.read_csv(\"Review.csv\")\n",
    "\n",
    "#Preview the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out the columns that we are interested in\n",
    "\n",
    "This includes _id, UserId, BusinessId, Rating, Text from the review table\n",
    "\n",
    "--> Store it in a dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          _id                  UserId  \\\n",
      "0      ENx8ZXpulmX5_AfCOp_U3A  mMjxhRn4h0LD1_jI3RT4cQ   \n",
      "1      Tjd32RIUDeOJrYpJ9J6_GA  tAr3zFVXoM1K2PrbyCdcTA   \n",
      "2      wYuRHgUSBTm6D8B-HrSpNg  1-5YghuD_7sLuD01f6hrJw   \n",
      "3      lisryzBzdpf4KNXfx6-3Fg  ZAaT3T_Yd1re0Nt_MOW7AA   \n",
      "4      thceOS2dozAixh8Qu09gOg  oRMf6hs2lgU3bIr_fF_5IA   \n",
      "5      7yAZ_47K_aJQlWGM79mYCA  oeAhRa8yFa9jtrhaHnOyxQ   \n",
      "6      NtBCMPJH_n62YA9Zy83jlw  8aBKh52ePGd3OG8di20wdw   \n",
      "7      5uOt1hm1LxR-H2NJEs1Vgw  pMltyeuU4SjT6Y8YVy7HBA   \n",
      "8      qWZ0yoP48ZLoGvj9QVc4TA  fZaWWxwwHGtH-8Vhx7qE_Q   \n",
      "9      MuIvIPQiYBXJDhicWjSX_g  m7rbZtL4b8du326Ng43SiA   \n",
      "10     EphGs01wv824ChsIm-bNxA  Q1oMmm7tKPOzA7_gqcV4zg   \n",
      "11     sVMv2XaWvEn3gGi8dnO3lA  Vtdm-QpN5yYxT-O00cuqFg   \n",
      "12     Z79DT0ECtm-1YDXFE9fEzA  wwdamcY73iJTyhl-3gGOJw   \n",
      "13     LeFrcXzAtIG26HKtYdpD6w  11R2R4nyRpF6nqlXH-JeGQ   \n",
      "14     i57jsdlQtxiSYWovohElAg  ITWi6Z_nZ8mmiSzpSUrDKg   \n",
      "15     CQ1njdQNZV-Z06VwDeC_5w  3S53VaMDPy8Lywk2TuPb4A   \n",
      "16     mbIUMsDU3CjAcq9bgwfwrA  nT-sNbcZDDo_9cWBPQSMQA   \n",
      "17     _gEmWdgfcWOsTxl731bMfA  Q1oMmm7tKPOzA7_gqcV4zg   \n",
      "18     3EyHqkbxK8dD1BcNXjCiNA  0V_C2aOTDKuR8CO3P3RvJw   \n",
      "19     XQbSUux2PCVhmUXndgmN-Q  tcl9C7lTC6BKq9AlnJFplQ   \n",
      "20     32hBO0c9PQfbR4ZoT-TSpQ  C1suecKrUtbxbPnma2KMMQ   \n",
      "21     7x9kaN0TaR0ztpPd6yeMzw  pMltyeuU4SjT6Y8YVy7HBA   \n",
      "22     FQ09qD1J5RAxreStjTAt0Q  HbI_aAcr8OhkCwRJ1eKU7g   \n",
      "23     L4JIlzcX_dpKvdPIl_q2Ww  sxRePE6Q6l0BlrAUXe4RwQ   \n",
      "24     YldT-MjKmNiqcv1v4cmyow  hVU5veeJhLndcBjAS1fLCg   \n",
      "25     uHH6V0Hsou9xFNvFvu5plw  3pvBUvU-dbtd1Ro9YeGdmQ   \n",
      "26     -csgGzn6gr0Ec4GoDLNI4A  H5giEryaio2xzYX6qKraPQ   \n",
      "27     Qx8anpmm_nCqf9VJEoTw3Q  Cd8OdDB6wJxurtAgU-IgHA   \n",
      "28     an0gCvNU7HhAIVj8VvqIcg  blxzOOhWwU_VtgVYxwL0AA   \n",
      "29     5OfvKh33VcdNk6oeEUgT5Q  Nv_gr_ujHLRQ8_y0MjfKnw   \n",
      "...                       ...                     ...   \n",
      "11326  IVteFL41cdoOUbEmlWeOEA  xRqBueZt0w-Ztdk46UGpdA   \n",
      "11327  AY8Wfn6DSMTkC7t4inV1mg  0PbJgJKl0L-vS-48pX8g8A   \n",
      "11328  L9GPnCTTau7fykUEaUvg7g  9evC7g5uOFAtp-UTbi1tWg   \n",
      "11329  riAwL4rymwtemYCFf74yEQ  tZ437GvGPzH9Hx11p32fdQ   \n",
      "11330  mXshURQ0EPwQk5Bhn9dMqA  0jmAZwCwQN9ByyWsLx7khA   \n",
      "11331  _fgpDO0QLoHmmWLjsPf2ZA  RACaZuc0YD9jRPAtaust5g   \n",
      "11332  cYgyP3gUCQswFF_crdoqPg  cfWkhUiMnwaMstTbvAYLUQ   \n",
      "11333  40kruop2KvofPNbYdmcbpw  AWPy2uveUH8ZLgNF9toO7g   \n",
      "11334  ij31JX4WDaTUPxTNcTb6Lw  wH-yhddRO8Uc2e4kjwf1RA   \n",
      "11335  iGTwGPZwS6Va85QHQ7j9QQ  0PbJgJKl0L-vS-48pX8g8A   \n",
      "11336  m2dPdGT1r8aDsj-NnCNMHA  dy_BrraKSl-I5Duq-xleKg   \n",
      "11337  wZvN1GJ6LM090-Tr42sxKg  4y4obgWxi_CL25nRHrhuEA   \n",
      "11338  S7FupdT_3u_3H-vHrhe4Tw  9evC7g5uOFAtp-UTbi1tWg   \n",
      "11339  bCrnWI8f-Pg696WjX-cwwQ  wH-yhddRO8Uc2e4kjwf1RA   \n",
      "11340  RFa-_q834hdaeKOtUUIC4g  bJ3vl-BshIHJdrZ9DEqRMQ   \n",
      "11341  6Sww_6O3dpJWM0Tpi5gVrw  t5XN2Lmv_VeXRSw9YdGf_w   \n",
      "11342  122pjwAU1kGmSJDuvkTr5g  EB3xsU98loQHCm6Ub1bJIA   \n",
      "11343  16QXGOpaRQTHTOFg8PPBBw  0PbJgJKl0L-vS-48pX8g8A   \n",
      "11344  KvRnVURiSBr2-Zuvzv-y1w  _6zTmwRscQUpbyo8etB0nQ   \n",
      "11345  jiwlDySoGVnfj5psdkSNbg  i0x6MWNiFLQ2cV3aIVjO5g   \n",
      "11346  syILyMC4LYgSoaKcAPTFAg  j8UlPZDO6K5iI8T7LKPqEA   \n",
      "11347  69opMjdEfTIenbCocPQt3w  v8H2waZrjUBU5-lbHo7ouw   \n",
      "11348  uWpeDZD2wDFmuDfoFY1KWQ  vTo_hR_R5GH4bjmo90HSLg   \n",
      "11349  BzVakTrfqksEmgvV_M0VmQ  j8UlPZDO6K5iI8T7LKPqEA   \n",
      "11350  fWKG9IQCnAkZoPIu0HBtUg  H8mXfh5XgGCqmMLwVH7k5A   \n",
      "11351  zdQyKZcvwhui5eZSUp-anA  KFZISl5mOUJ6bu3qCUrO-g   \n",
      "11352  emLmgU4MXeMOoyJzvDxQXA  hC1HjO-Tye6dar3Bg0aZMw   \n",
      "11353  sIPb4dcxpuQNIfCwIOKHgQ  J-NdrqdYuaBZnD8zo9pgjg   \n",
      "11354  v_peLyCt7NX6PpXSGgVxuQ  L5qnan1MZhuF8LetcU-Ziw   \n",
      "11355  ENb1ylDF2Y8S1x_z8T9uVQ  tZ437GvGPzH9Hx11p32fdQ   \n",
      "\n",
      "                                    BusinessId  Rating  \\\n",
      "0                 long-beach-seafood-singapore       5   \n",
      "1                 long-beach-seafood-singapore       5   \n",
      "2                 long-beach-seafood-singapore       5   \n",
      "3                 long-beach-seafood-singapore       3   \n",
      "4                 long-beach-seafood-singapore       4   \n",
      "5                 long-beach-seafood-singapore       5   \n",
      "6                        tong-heng-singapore-2       4   \n",
      "7                        tong-heng-singapore-2       5   \n",
      "8                        tong-heng-singapore-2       5   \n",
      "9                        tong-heng-singapore-2       3   \n",
      "10                       tong-heng-singapore-2       4   \n",
      "11                       tong-heng-singapore-2       4   \n",
      "12                       tong-heng-singapore-2       5   \n",
      "13                       tong-heng-singapore-2       3   \n",
      "14                       tong-heng-singapore-2       4   \n",
      "15                    straitskitchen-singapore       4   \n",
      "16                    straitskitchen-singapore       4   \n",
      "17                    straitskitchen-singapore       4   \n",
      "18                    straitskitchen-singapore       4   \n",
      "19                    straitskitchen-singapore       5   \n",
      "20                    straitskitchen-singapore       5   \n",
      "21                    straitskitchen-singapore       4   \n",
      "22                    straitskitchen-singapore       3   \n",
      "23                    straitskitchen-singapore       5   \n",
      "24                    straitskitchen-singapore       5   \n",
      "25                    straitskitchen-singapore       5   \n",
      "26                    pizzeria-mozza-singapore       2   \n",
      "27                    pizzeria-mozza-singapore       5   \n",
      "28                    pizzeria-mozza-singapore       3   \n",
      "29                    pizzeria-mozza-singapore       3   \n",
      "...                                        ...     ...   \n",
      "11326      black-canyon-restaurant-johor-bahru       4   \n",
      "11327                    noms-bistro-singapore       4   \n",
      "11328                 joyus-pastries-singapore       3   \n",
      "11329                       bake-inc-singapore       2   \n",
      "11330                       bake-inc-singapore       3   \n",
      "11331              et-artisan-sweets-singapore       4   \n",
      "11332              et-artisan-sweets-singapore       5   \n",
      "11333                    famous-amos-singapore       3   \n",
      "11334     qin-carrot-cake-and-popiah-singapore       3   \n",
      "11335             angie-the-choice-singapore-2       3   \n",
      "11336                 champion-bread-singapore       4   \n",
      "11337           song-han-carrot-cake-singapore       3   \n",
      "11338           four-seasons-durians-singapore       3   \n",
      "11339               paris-baguette-singapore-2       1   \n",
      "11340                     bakerzin-singapore-4       1   \n",
      "11341                     bakerzin-singapore-4       3   \n",
      "11342                     bakerzin-singapore-4       3   \n",
      "11343                      ecreative-singapore       3   \n",
      "11344            awfully-chocolate-singapore-2       3   \n",
      "11345                       cedele-singapore-3       3   \n",
      "11346                 baker-talent-singapore-3       5   \n",
      "11347                   baker-talent-singapore       2   \n",
      "11348                   baker-talent-singapore       3   \n",
      "11349                fancy-delight-singapore-5       4   \n",
      "11350                 crystal-jade-singapore-3       4   \n",
      "11351                    breadtalk-singapore-9       2   \n",
      "11352  tay-hock-choon-market-produce-singapore       3   \n",
      "11353    yamazaki-boulangerie-chaude-singapore       4   \n",
      "11354    yamazaki-boulangerie-chaude-singapore       3   \n",
      "11355                kedai-kue-kue-singapore-2       3   \n",
      "\n",
      "                                                    Text  \n",
      "0      Been coming here for more than a decade. Long ...  \n",
      "1      I've been coming here with my boyfriend to onl...  \n",
      "2      MUST GO! Your life isn't complete without goin...  \n",
      "3      Excellent service, our waiter was always aroun...  \n",
      "4      Try the Chilli crab. Its gravy was on the swee...  \n",
      "5      It's all about fingering the crabs baby! You c...  \n",
      "6      You can probably get the best egg tarts in Sin...  \n",
      "7      Excellent quality custard tarts which come in ...  \n",
      "8      Love the omelet kaya toast. The toast is super...  \n",
      "9      The diamond shape is cute! But it kinda makes ...  \n",
      "10     Just get the egg tarts. Forget about the rest....  \n",
      "11     Located near Maxwell Food Centre and in the vi...  \n",
      "12     I can't believe I completely forgot to write a...  \n",
      "13     Service/ Ive seen comments on good service but...  \n",
      "14     Yesss!! Their egg tarts were amazing!! I highl...  \n",
      "15     As I've said in a previous review, I am not a ...  \n",
      "16     Offers a wide variety of items for buffet lunc...  \n",
      "17     I still think Straits Kitchen (halal restauran...  \n",
      "18     Had a reservation here one Sunday in June. Hos...  \n",
      "19     Fantastic restaurant with excellent selection ...  \n",
      "20     StraitsKitchen is located inside the Grand Hya...  \n",
      "21     StraitsRestaurant is the Grand Hyatt's all you...  \n",
      "22     Great place to get your local food fix in an a...  \n",
      "23     I stayed at the hyatt for a few nights and whi...  \n",
      "24     StraitsKitchen in the Grand Hyatt is worth the...  \n",
      "25     Great Singapore local halal food......all in o...  \n",
      "26     I was quite happy that I finally managed to tr...  \n",
      "27     Mozza Pizzeria is a celebrity restaurant in MB...  \n",
      "28     Pizzeria Mozza completely blew us away when we...  \n",
      "29     The pizza was disappointing, which for a pizze...  \n",
      "...                                                  ...  \n",
      "11326  One of my favorite restaurants in Aeon Bukit I...  \n",
      "11327  Feeling exhausted and hungry after my morning ...  \n",
      "11328  You will be able to spot two type of product w...  \n",
      "11329  One of a few outlets, Bake Inc is a cheaper al...  \n",
      "11330  Not bad options for pastries. Have come here a...  \n",
      "11331  I LOVE THEIR MACARONS!!! Okay, I can't imagine...  \n",
      "11332  This place deserves to be 5 stars because they...  \n",
      "11333  How soft and chewy would you want it to be? Or...  \n",
      "11334  Black carrot cake - nice, plenty of charred bi...  \n",
      "11335  My friends wanted to come over at my place to ...  \n",
      "11336  This is one of my favourite bakeries. There's ...  \n",
      "11337  I guess they try to be different by adding cur...  \n",
      "11338  I never liked durian products although I take ...  \n",
      "11339  Bought a $10 earl grey chiffon cake before, it...  \n",
      "11340  Having known for the desserts, my friends and ...  \n",
      "11341  Bakerzin Enjoyed a slow dinner by myself and o...  \n",
      "11342  A little squeeze. Weird smell within the outle...  \n",
      "11343  Looking for some snacks to bring home, I stumb...  \n",
      "11344  Awfully Chocolate is famous for their chocolat...  \n",
      "11345  I wish I didn't have to remove a star as I do ...  \n",
      "11346  Never been a fan of Breadtalk and their overly...  \n",
      "11347  There's always a bit of a queue here, but that...  \n",
      "11348  I've stayed in Choa Chu Kang for more than 7 y...  \n",
      "11349  For most people, when it comes to egg tarts, i...  \n",
      "11350  Located near the first floor car park entrance...  \n",
      "11351  Based on the two pastries I purchased here, it...  \n",
      "11352  This stall sells biscuits of varying shapes an...  \n",
      "11353  I was walking around Tamp 1 one day and someth...  \n",
      "11354  Yamazaki bread was my favorite. Yeah, you spot...  \n",
      "11355  The kues here are decent - its good that its g...  \n",
      "\n",
      "[11356 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Select only those important columns for our project\n",
    "df1 = data[['_id','UserId','BusinessId','Rating','Text']]\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data folder for easy processing\n",
    "Data are stored as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 32.239083377004135\n"
     ]
    }
   ],
   "source": [
    "# Make a directory to store the corpus files\n",
    "# Creating individual review files \n",
    "# Need to delete Data folder before adding the files again**\n",
    "import os\n",
    "import shutil\n",
    "import timeit\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import collections\n",
    "\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if os.path.exists(directory):\n",
    "            shutil.rmtree(directory)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "        \n",
    "\n",
    "# Create a folder as a corpus\n",
    "# Creates a folder in the current directory called Data\n",
    "createFolder('./Data/')\n",
    "\n",
    "allSentenceData = []\n",
    "allSentenceReviewId = []\n",
    "allSentenceBusinessId = []\n",
    "allSentenceRating = []\n",
    "\n",
    "reviewSentenceList = []\n",
    "\n",
    "def CreateCorpusFromDataFrame(corpusfolder,df1):\n",
    "    \n",
    "    reviewPartDictionary = collections.OrderedDict();\n",
    "    \n",
    "    \n",
    "    for index, r in df1.iterrows():\n",
    "        reviewId = r['_id']\n",
    "        businessId = r['BusinessId']\n",
    "        userId = r['UserId']\n",
    "        rating = r['Rating']\n",
    "        body = r['Text']\n",
    "        \n",
    "        sentenceList = sent_tokenize(body)\n",
    "        numberOfSentences = len(sentenceList)\n",
    "        \n",
    "        reviewPartDictionary[str(reviewId)] = numberOfSentences;\n",
    "        \n",
    "        for i in range(0, numberOfSentences):\n",
    "            fname=str(reviewId) + '#' + str(i) + '.txt'\n",
    "            reviewSentenceList.append(fname)\n",
    "            corpusfile=open(corpusfolder+'/'+fname,'a')\n",
    "            corpusfile.write(sentenceList[i])\n",
    "            corpusfile.close()\n",
    "            allSentenceData.append(sentenceList[i])\n",
    "            allSentenceReviewId.append(reviewId)\n",
    "            allSentenceBusinessId.append(businessId)\n",
    "            allSentenceRating.append(rating)\n",
    "            \n",
    "        \n",
    "    return reviewPartDictionary\n",
    "        \n",
    "start_time = timeit.default_timer()\n",
    "reviewDict = CreateCorpusFromDataFrame('./Data',df1)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time Taken: \"+ str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 0.0030276400066213682\n"
     ]
    }
   ],
   "source": [
    "#Function To Preprocess allSentenceData\n",
    "import nltk\n",
    "import re\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('^[a-z]+$', token.lower()):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('^[a-z]+$', token.lower()):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time Taken: \"+ str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====  Tonkenized ==== \n",
      "1893531\n",
      "=====  Stemmed ==== \n",
      "1893531\n",
      "Time Taken: 74.23346280799888\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  Dataframe of vocabulary - Stemmed, tokenized\n",
    "#\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for sentence in allSentenceData:\n",
    "    allwords_stemmed = tokenize_and_stem(sentence) # for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) # extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(sentence)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)\n",
    "    \n",
    "print(\"=====  Tonkenized ==== \")\n",
    "print(len(totalvocab_tokenized))\n",
    "\n",
    "print(\"=====  Stemmed ==== \")\n",
    "print(len(totalvocab_stemmed))  \n",
    "\n",
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "\n",
    "# print(vocab_frame)\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time Taken: \"+ str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         aa  aa friend  aa good  aaaaaaaaaaaaargh  aaaaaaaaaaaaargh minut  \\\n",
      "0       0.0        0.0      0.0               0.0                     0.0   \n",
      "1       0.0        0.0      0.0               0.0                     0.0   \n",
      "2       0.0        0.0      0.0               0.0                     0.0   \n",
      "3       0.0        0.0      0.0               0.0                     0.0   \n",
      "4       0.0        0.0      0.0               0.0                     0.0   \n",
      "5       0.0        0.0      0.0               0.0                     0.0   \n",
      "6       0.0        0.0      0.0               0.0                     0.0   \n",
      "7       0.0        0.0      0.0               0.0                     0.0   \n",
      "8       0.0        0.0      0.0               0.0                     0.0   \n",
      "9       0.0        0.0      0.0               0.0                     0.0   \n",
      "10      0.0        0.0      0.0               0.0                     0.0   \n",
      "11      0.0        0.0      0.0               0.0                     0.0   \n",
      "12      0.0        0.0      0.0               0.0                     0.0   \n",
      "13      0.0        0.0      0.0               0.0                     0.0   \n",
      "14      0.0        0.0      0.0               0.0                     0.0   \n",
      "15      0.0        0.0      0.0               0.0                     0.0   \n",
      "16      0.0        0.0      0.0               0.0                     0.0   \n",
      "17      0.0        0.0      0.0               0.0                     0.0   \n",
      "18      0.0        0.0      0.0               0.0                     0.0   \n",
      "19      0.0        0.0      0.0               0.0                     0.0   \n",
      "20      0.0        0.0      0.0               0.0                     0.0   \n",
      "21      0.0        0.0      0.0               0.0                     0.0   \n",
      "22      0.0        0.0      0.0               0.0                     0.0   \n",
      "23      0.0        0.0      0.0               0.0                     0.0   \n",
      "24      0.0        0.0      0.0               0.0                     0.0   \n",
      "25      0.0        0.0      0.0               0.0                     0.0   \n",
      "26      0.0        0.0      0.0               0.0                     0.0   \n",
      "27      0.0        0.0      0.0               0.0                     0.0   \n",
      "28      0.0        0.0      0.0               0.0                     0.0   \n",
      "29      0.0        0.0      0.0               0.0                     0.0   \n",
      "...     ...        ...      ...               ...                     ...   \n",
      "130934  0.0        0.0      0.0               0.0                     0.0   \n",
      "130935  0.0        0.0      0.0               0.0                     0.0   \n",
      "130936  0.0        0.0      0.0               0.0                     0.0   \n",
      "130937  0.0        0.0      0.0               0.0                     0.0   \n",
      "130938  0.0        0.0      0.0               0.0                     0.0   \n",
      "130939  0.0        0.0      0.0               0.0                     0.0   \n",
      "130940  0.0        0.0      0.0               0.0                     0.0   \n",
      "130941  0.0        0.0      0.0               0.0                     0.0   \n",
      "130942  0.0        0.0      0.0               0.0                     0.0   \n",
      "130943  0.0        0.0      0.0               0.0                     0.0   \n",
      "130944  0.0        0.0      0.0               0.0                     0.0   \n",
      "130945  0.0        0.0      0.0               0.0                     0.0   \n",
      "130946  0.0        0.0      0.0               0.0                     0.0   \n",
      "130947  0.0        0.0      0.0               0.0                     0.0   \n",
      "130948  0.0        0.0      0.0               0.0                     0.0   \n",
      "130949  0.0        0.0      0.0               0.0                     0.0   \n",
      "130950  0.0        0.0      0.0               0.0                     0.0   \n",
      "130951  0.0        0.0      0.0               0.0                     0.0   \n",
      "130952  0.0        0.0      0.0               0.0                     0.0   \n",
      "130953  0.0        0.0      0.0               0.0                     0.0   \n",
      "130954  0.0        0.0      0.0               0.0                     0.0   \n",
      "130955  0.0        0.0      0.0               0.0                     0.0   \n",
      "130956  0.0        0.0      0.0               0.0                     0.0   \n",
      "130957  0.0        0.0      0.0               0.0                     0.0   \n",
      "130958  0.0        0.0      0.0               0.0                     0.0   \n",
      "130959  0.0        0.0      0.0               0.0                     0.0   \n",
      "130960  0.0        0.0      0.0               0.0                     0.0   \n",
      "130961  0.0        0.0      0.0               0.0                     0.0   \n",
      "130962  0.0        0.0      0.0               0.0                     0.0   \n",
      "130963  0.0        0.0      0.0               0.0                     0.0   \n",
      "\n",
      "        aaaaaaaaaaaaargh minut later  aaaaaaah  aaaaannndddd  \\\n",
      "0                                0.0       0.0           0.0   \n",
      "1                                0.0       0.0           0.0   \n",
      "2                                0.0       0.0           0.0   \n",
      "3                                0.0       0.0           0.0   \n",
      "4                                0.0       0.0           0.0   \n",
      "5                                0.0       0.0           0.0   \n",
      "6                                0.0       0.0           0.0   \n",
      "7                                0.0       0.0           0.0   \n",
      "8                                0.0       0.0           0.0   \n",
      "9                                0.0       0.0           0.0   \n",
      "10                               0.0       0.0           0.0   \n",
      "11                               0.0       0.0           0.0   \n",
      "12                               0.0       0.0           0.0   \n",
      "13                               0.0       0.0           0.0   \n",
      "14                               0.0       0.0           0.0   \n",
      "15                               0.0       0.0           0.0   \n",
      "16                               0.0       0.0           0.0   \n",
      "17                               0.0       0.0           0.0   \n",
      "18                               0.0       0.0           0.0   \n",
      "19                               0.0       0.0           0.0   \n",
      "20                               0.0       0.0           0.0   \n",
      "21                               0.0       0.0           0.0   \n",
      "22                               0.0       0.0           0.0   \n",
      "23                               0.0       0.0           0.0   \n",
      "24                               0.0       0.0           0.0   \n",
      "25                               0.0       0.0           0.0   \n",
      "26                               0.0       0.0           0.0   \n",
      "27                               0.0       0.0           0.0   \n",
      "28                               0.0       0.0           0.0   \n",
      "29                               0.0       0.0           0.0   \n",
      "...                              ...       ...           ...   \n",
      "130934                           0.0       0.0           0.0   \n",
      "130935                           0.0       0.0           0.0   \n",
      "130936                           0.0       0.0           0.0   \n",
      "130937                           0.0       0.0           0.0   \n",
      "130938                           0.0       0.0           0.0   \n",
      "130939                           0.0       0.0           0.0   \n",
      "130940                           0.0       0.0           0.0   \n",
      "130941                           0.0       0.0           0.0   \n",
      "130942                           0.0       0.0           0.0   \n",
      "130943                           0.0       0.0           0.0   \n",
      "130944                           0.0       0.0           0.0   \n",
      "130945                           0.0       0.0           0.0   \n",
      "130946                           0.0       0.0           0.0   \n",
      "130947                           0.0       0.0           0.0   \n",
      "130948                           0.0       0.0           0.0   \n",
      "130949                           0.0       0.0           0.0   \n",
      "130950                           0.0       0.0           0.0   \n",
      "130951                           0.0       0.0           0.0   \n",
      "130952                           0.0       0.0           0.0   \n",
      "130953                           0.0       0.0           0.0   \n",
      "130954                           0.0       0.0           0.0   \n",
      "130955                           0.0       0.0           0.0   \n",
      "130956                           0.0       0.0           0.0   \n",
      "130957                           0.0       0.0           0.0   \n",
      "130958                           0.0       0.0           0.0   \n",
      "130959                           0.0       0.0           0.0   \n",
      "130960                           0.0       0.0           0.0   \n",
      "130961                           0.0       0.0           0.0   \n",
      "130962                           0.0       0.0           0.0   \n",
      "130963                           0.0       0.0           0.0   \n",
      "\n",
      "        aaaaannndddd felt  aaaaannndddd felt huge  ...  zzimdak boneless  \\\n",
      "0                     0.0                     0.0  ...               0.0   \n",
      "1                     0.0                     0.0  ...               0.0   \n",
      "2                     0.0                     0.0  ...               0.0   \n",
      "3                     0.0                     0.0  ...               0.0   \n",
      "4                     0.0                     0.0  ...               0.0   \n",
      "5                     0.0                     0.0  ...               0.0   \n",
      "6                     0.0                     0.0  ...               0.0   \n",
      "7                     0.0                     0.0  ...               0.0   \n",
      "8                     0.0                     0.0  ...               0.0   \n",
      "9                     0.0                     0.0  ...               0.0   \n",
      "10                    0.0                     0.0  ...               0.0   \n",
      "11                    0.0                     0.0  ...               0.0   \n",
      "12                    0.0                     0.0  ...               0.0   \n",
      "13                    0.0                     0.0  ...               0.0   \n",
      "14                    0.0                     0.0  ...               0.0   \n",
      "15                    0.0                     0.0  ...               0.0   \n",
      "16                    0.0                     0.0  ...               0.0   \n",
      "17                    0.0                     0.0  ...               0.0   \n",
      "18                    0.0                     0.0  ...               0.0   \n",
      "19                    0.0                     0.0  ...               0.0   \n",
      "20                    0.0                     0.0  ...               0.0   \n",
      "21                    0.0                     0.0  ...               0.0   \n",
      "22                    0.0                     0.0  ...               0.0   \n",
      "23                    0.0                     0.0  ...               0.0   \n",
      "24                    0.0                     0.0  ...               0.0   \n",
      "25                    0.0                     0.0  ...               0.0   \n",
      "26                    0.0                     0.0  ...               0.0   \n",
      "27                    0.0                     0.0  ...               0.0   \n",
      "28                    0.0                     0.0  ...               0.0   \n",
      "29                    0.0                     0.0  ...               0.0   \n",
      "...                   ...                     ...  ...               ...   \n",
      "130934                0.0                     0.0  ...               0.0   \n",
      "130935                0.0                     0.0  ...               0.0   \n",
      "130936                0.0                     0.0  ...               0.0   \n",
      "130937                0.0                     0.0  ...               0.0   \n",
      "130938                0.0                     0.0  ...               0.0   \n",
      "130939                0.0                     0.0  ...               0.0   \n",
      "130940                0.0                     0.0  ...               0.0   \n",
      "130941                0.0                     0.0  ...               0.0   \n",
      "130942                0.0                     0.0  ...               0.0   \n",
      "130943                0.0                     0.0  ...               0.0   \n",
      "130944                0.0                     0.0  ...               0.0   \n",
      "130945                0.0                     0.0  ...               0.0   \n",
      "130946                0.0                     0.0  ...               0.0   \n",
      "130947                0.0                     0.0  ...               0.0   \n",
      "130948                0.0                     0.0  ...               0.0   \n",
      "130949                0.0                     0.0  ...               0.0   \n",
      "130950                0.0                     0.0  ...               0.0   \n",
      "130951                0.0                     0.0  ...               0.0   \n",
      "130952                0.0                     0.0  ...               0.0   \n",
      "130953                0.0                     0.0  ...               0.0   \n",
      "130954                0.0                     0.0  ...               0.0   \n",
      "130955                0.0                     0.0  ...               0.0   \n",
      "130956                0.0                     0.0  ...               0.0   \n",
      "130957                0.0                     0.0  ...               0.0   \n",
      "130958                0.0                     0.0  ...               0.0   \n",
      "130959                0.0                     0.0  ...               0.0   \n",
      "130960                0.0                     0.0  ...               0.0   \n",
      "130961                0.0                     0.0  ...               0.0   \n",
      "130962                0.0                     0.0  ...               0.0   \n",
      "130963                0.0                     0.0  ...               0.0   \n",
      "\n",
      "        zzimdak boneless chicken  zzimdak seafood  zzimdak seafood zzimdak  \\\n",
      "0                            0.0              0.0                      0.0   \n",
      "1                            0.0              0.0                      0.0   \n",
      "2                            0.0              0.0                      0.0   \n",
      "3                            0.0              0.0                      0.0   \n",
      "4                            0.0              0.0                      0.0   \n",
      "5                            0.0              0.0                      0.0   \n",
      "6                            0.0              0.0                      0.0   \n",
      "7                            0.0              0.0                      0.0   \n",
      "8                            0.0              0.0                      0.0   \n",
      "9                            0.0              0.0                      0.0   \n",
      "10                           0.0              0.0                      0.0   \n",
      "11                           0.0              0.0                      0.0   \n",
      "12                           0.0              0.0                      0.0   \n",
      "13                           0.0              0.0                      0.0   \n",
      "14                           0.0              0.0                      0.0   \n",
      "15                           0.0              0.0                      0.0   \n",
      "16                           0.0              0.0                      0.0   \n",
      "17                           0.0              0.0                      0.0   \n",
      "18                           0.0              0.0                      0.0   \n",
      "19                           0.0              0.0                      0.0   \n",
      "20                           0.0              0.0                      0.0   \n",
      "21                           0.0              0.0                      0.0   \n",
      "22                           0.0              0.0                      0.0   \n",
      "23                           0.0              0.0                      0.0   \n",
      "24                           0.0              0.0                      0.0   \n",
      "25                           0.0              0.0                      0.0   \n",
      "26                           0.0              0.0                      0.0   \n",
      "27                           0.0              0.0                      0.0   \n",
      "28                           0.0              0.0                      0.0   \n",
      "29                           0.0              0.0                      0.0   \n",
      "...                          ...              ...                      ...   \n",
      "130934                       0.0              0.0                      0.0   \n",
      "130935                       0.0              0.0                      0.0   \n",
      "130936                       0.0              0.0                      0.0   \n",
      "130937                       0.0              0.0                      0.0   \n",
      "130938                       0.0              0.0                      0.0   \n",
      "130939                       0.0              0.0                      0.0   \n",
      "130940                       0.0              0.0                      0.0   \n",
      "130941                       0.0              0.0                      0.0   \n",
      "130942                       0.0              0.0                      0.0   \n",
      "130943                       0.0              0.0                      0.0   \n",
      "130944                       0.0              0.0                      0.0   \n",
      "130945                       0.0              0.0                      0.0   \n",
      "130946                       0.0              0.0                      0.0   \n",
      "130947                       0.0              0.0                      0.0   \n",
      "130948                       0.0              0.0                      0.0   \n",
      "130949                       0.0              0.0                      0.0   \n",
      "130950                       0.0              0.0                      0.0   \n",
      "130951                       0.0              0.0                      0.0   \n",
      "130952                       0.0              0.0                      0.0   \n",
      "130953                       0.0              0.0                      0.0   \n",
      "130954                       0.0              0.0                      0.0   \n",
      "130955                       0.0              0.0                      0.0   \n",
      "130956                       0.0              0.0                      0.0   \n",
      "130957                       0.0              0.0                      0.0   \n",
      "130958                       0.0              0.0                      0.0   \n",
      "130959                       0.0              0.0                      0.0   \n",
      "130960                       0.0              0.0                      0.0   \n",
      "130961                       0.0              0.0                      0.0   \n",
      "130962                       0.0              0.0                      0.0   \n",
      "130963                       0.0              0.0                      0.0   \n",
      "\n",
      "        zzimdak spici  zzimdak spici chicken  zzu  zzu sam  zzu sam hot  \\\n",
      "0                 0.0                    0.0  0.0      0.0          0.0   \n",
      "1                 0.0                    0.0  0.0      0.0          0.0   \n",
      "2                 0.0                    0.0  0.0      0.0          0.0   \n",
      "3                 0.0                    0.0  0.0      0.0          0.0   \n",
      "4                 0.0                    0.0  0.0      0.0          0.0   \n",
      "5                 0.0                    0.0  0.0      0.0          0.0   \n",
      "6                 0.0                    0.0  0.0      0.0          0.0   \n",
      "7                 0.0                    0.0  0.0      0.0          0.0   \n",
      "8                 0.0                    0.0  0.0      0.0          0.0   \n",
      "9                 0.0                    0.0  0.0      0.0          0.0   \n",
      "10                0.0                    0.0  0.0      0.0          0.0   \n",
      "11                0.0                    0.0  0.0      0.0          0.0   \n",
      "12                0.0                    0.0  0.0      0.0          0.0   \n",
      "13                0.0                    0.0  0.0      0.0          0.0   \n",
      "14                0.0                    0.0  0.0      0.0          0.0   \n",
      "15                0.0                    0.0  0.0      0.0          0.0   \n",
      "16                0.0                    0.0  0.0      0.0          0.0   \n",
      "17                0.0                    0.0  0.0      0.0          0.0   \n",
      "18                0.0                    0.0  0.0      0.0          0.0   \n",
      "19                0.0                    0.0  0.0      0.0          0.0   \n",
      "20                0.0                    0.0  0.0      0.0          0.0   \n",
      "21                0.0                    0.0  0.0      0.0          0.0   \n",
      "22                0.0                    0.0  0.0      0.0          0.0   \n",
      "23                0.0                    0.0  0.0      0.0          0.0   \n",
      "24                0.0                    0.0  0.0      0.0          0.0   \n",
      "25                0.0                    0.0  0.0      0.0          0.0   \n",
      "26                0.0                    0.0  0.0      0.0          0.0   \n",
      "27                0.0                    0.0  0.0      0.0          0.0   \n",
      "28                0.0                    0.0  0.0      0.0          0.0   \n",
      "29                0.0                    0.0  0.0      0.0          0.0   \n",
      "...               ...                    ...  ...      ...          ...   \n",
      "130934            0.0                    0.0  0.0      0.0          0.0   \n",
      "130935            0.0                    0.0  0.0      0.0          0.0   \n",
      "130936            0.0                    0.0  0.0      0.0          0.0   \n",
      "130937            0.0                    0.0  0.0      0.0          0.0   \n",
      "130938            0.0                    0.0  0.0      0.0          0.0   \n",
      "130939            0.0                    0.0  0.0      0.0          0.0   \n",
      "130940            0.0                    0.0  0.0      0.0          0.0   \n",
      "130941            0.0                    0.0  0.0      0.0          0.0   \n",
      "130942            0.0                    0.0  0.0      0.0          0.0   \n",
      "130943            0.0                    0.0  0.0      0.0          0.0   \n",
      "130944            0.0                    0.0  0.0      0.0          0.0   \n",
      "130945            0.0                    0.0  0.0      0.0          0.0   \n",
      "130946            0.0                    0.0  0.0      0.0          0.0   \n",
      "130947            0.0                    0.0  0.0      0.0          0.0   \n",
      "130948            0.0                    0.0  0.0      0.0          0.0   \n",
      "130949            0.0                    0.0  0.0      0.0          0.0   \n",
      "130950            0.0                    0.0  0.0      0.0          0.0   \n",
      "130951            0.0                    0.0  0.0      0.0          0.0   \n",
      "130952            0.0                    0.0  0.0      0.0          0.0   \n",
      "130953            0.0                    0.0  0.0      0.0          0.0   \n",
      "130954            0.0                    0.0  0.0      0.0          0.0   \n",
      "130955            0.0                    0.0  0.0      0.0          0.0   \n",
      "130956            0.0                    0.0  0.0      0.0          0.0   \n",
      "130957            0.0                    0.0  0.0      0.0          0.0   \n",
      "130958            0.0                    0.0  0.0      0.0          0.0   \n",
      "130959            0.0                    0.0  0.0      0.0          0.0   \n",
      "130960            0.0                    0.0  0.0      0.0          0.0   \n",
      "130961            0.0                    0.0  0.0      0.0          0.0   \n",
      "130962            0.0                    0.0  0.0      0.0          0.0   \n",
      "130963            0.0                    0.0  0.0      0.0          0.0   \n",
      "\n",
      "        zzu sam small  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n",
      "3                 0.0  \n",
      "4                 0.0  \n",
      "5                 0.0  \n",
      "6                 0.0  \n",
      "7                 0.0  \n",
      "8                 0.0  \n",
      "9                 0.0  \n",
      "10                0.0  \n",
      "11                0.0  \n",
      "12                0.0  \n",
      "13                0.0  \n",
      "14                0.0  \n",
      "15                0.0  \n",
      "16                0.0  \n",
      "17                0.0  \n",
      "18                0.0  \n",
      "19                0.0  \n",
      "20                0.0  \n",
      "21                0.0  \n",
      "22                0.0  \n",
      "23                0.0  \n",
      "24                0.0  \n",
      "25                0.0  \n",
      "26                0.0  \n",
      "27                0.0  \n",
      "28                0.0  \n",
      "29                0.0  \n",
      "...               ...  \n",
      "130934            0.0  \n",
      "130935            0.0  \n",
      "130936            0.0  \n",
      "130937            0.0  \n",
      "130938            0.0  \n",
      "130939            0.0  \n",
      "130940            0.0  \n",
      "130941            0.0  \n",
      "130942            0.0  \n",
      "130943            0.0  \n",
      "130944            0.0  \n",
      "130945            0.0  \n",
      "130946            0.0  \n",
      "130947            0.0  \n",
      "130948            0.0  \n",
      "130949            0.0  \n",
      "130950            0.0  \n",
      "130951            0.0  \n",
      "130952            0.0  \n",
      "130953            0.0  \n",
      "130954            0.0  \n",
      "130955            0.0  \n",
      "130956            0.0  \n",
      "130957            0.0  \n",
      "130958            0.0  \n",
      "130959            0.0  \n",
      "130960            0.0  \n",
      "130961            0.0  \n",
      "130962            0.0  \n",
      "130963            0.0  \n",
      "\n",
      "[130964 rows x 1073166 columns]\n"
     ]
    }
   ],
   "source": [
    "#Testing out other python library with kmeans and viz\n",
    "#https://radimrehurek.com/gensim/sklearn_api/w2vmodel.html\n",
    "#https://www.kaggle.com/dipikabaad0107/elbow-curve-for-text-clustering\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "import nltk\n",
    "import re\n",
    "import pylab as pl\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "#Small data set\n",
    "dataLimit = None\n",
    "smallData = allSentenceData[0:dataLimit]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english',use_idf=True,tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "tfidf_matrix = vectorizer.fit_transform(smallData)\n",
    "# print(tfidf_matrix.shape)\n",
    "# print(type(tfidf_matrix))\n",
    "\n",
    "\n",
    "terms = vectorizer.get_feature_names() #Get all the features / vocab i think\n",
    "\n",
    "tfidf_dataframe = pd.DataFrame(tfidf_matrix.toarray(), columns = terms)\n",
    "print(tfidf_dataframe)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing of Elbow Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://www.kaggle.com/dipikabaad0107/elbow-curve-for-text-clustering\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "distortions = []\n",
    "K = range(1,11)\n",
    "for i in K:\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300,n_init=10,random_state=0)\n",
    "    kmeans.fit(tfidf_matrix)\n",
    "    distortions.append(kmeans.inertia_)\n",
    "pl.plot(K,distortions)\n",
    "pl.title('ELBOW')\n",
    "pl.xlabel('Number of Clusters')\n",
    "pl.ylabel('distortions')\n",
    "pl.show()\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(\"Time Taken: \"+ str(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Methods\n",
    "## (A) K-Means Clustering\n",
    "Based on the above elbow curve, we determine the optimal number to be 6 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 11s, sys: 20.9 s, total: 8min 32s\n",
      "Wall time: 4min 25s\n"
     ]
    }
   ],
   "source": [
    "# Based on the elbow method, I determine the optimal number to be 4/5\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "num_clusters = 6\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS TO PRINT CLUSTER + REVIEW DATA\n",
    "for i in range(0 , len(smallData)):\n",
    "    print(\"Cluster: \" + str(clusters[i]) +\" \" + smallData[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# ===================\n",
    "# K MEANS CLUSTERING\n",
    "# ===================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "reviews = { 'businessId': allSentenceBusinessId[0:dataLimit], 'rating': allSentenceRating[0:dataLimit], 'sentence': allSentenceData[0:dataLimit], 'sentenceNumber': allSentenceDataSentenceNum, 'reviewId':allSentenceReviewId[0:dataLimit], 'cluster': clusters[0:dataLimit] }\n",
    "\n",
    "frame = pd.DataFrame(reviews, index = [clusters[0:dataLimit]] , columns = ['rating', 'sentence', 'sentenceNumber', 'reviewId', 'businessId', 'cluster'])\n",
    "\n",
    "os.remove(\"output.csv\")\n",
    "for index, row in frame.iterrows():\n",
    "    rowFrame = row.to_frame()\n",
    "    rowFrame = rowFrame.transpose()\n",
    "    rowFrame.to_csv(\"output.csv\", mode='a', header=False)\n",
    "    \n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Loading Cluster 0 words...\n",
      "\n",
      "Loading Cluster 1 words...\n",
      "\n",
      "Loading Cluster 2 words...\n",
      "\n",
      "Loading Cluster 3 words...\n",
      "\n",
      "Loading Cluster 4 words...\n",
      "\n",
      "Loading Cluster 5 words...\n",
      "\n",
      "Exporting to csv file: output2.csv\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "terms_words = []\n",
    "terms_values = {}\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Loading Cluster %d words...\" %i)\n",
    "    wordList = [vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0] for ind in order_centroids[i, :10]]\n",
    "    terms_values[i] = wordList\n",
    "\n",
    "terms_df = pd.DataFrame(terms_values)\n",
    "FILE_NAME = \"output2.csv\"\n",
    "print(\"Exporting to csv file: %s\" %FILE_NAME)\n",
    "\n",
    "terms_df.to_csv(FILE_NAME)\n",
    "\n",
    "print(\"Complete\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Top Words\n",
    "#### Method 1: TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_frequency_dict = {}\n",
    "\n",
    "for i in range(num_clusters):\n",
    "\n",
    "    sub_frame = frame.loc[frame['cluster'] == i]\n",
    "    sub_data = sub_frame['sentence'].tolist()\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english',use_idf=True,tokenizer=tokenize_and_stem)\n",
    "    tfidf_matrix = vectorizer.fit_transform(sub_data)\n",
    "\n",
    "    feature_name_list = vectorizer.get_feature_names()\n",
    "\n",
    "    tfidf_dataframe = pd.DataFrame(tfidf_matrix.toarray(), columns = feature_name_list)\n",
    "\n",
    "\n",
    "    count_frame = sub_frame.sentence.str.split(expand=True).stack().value_counts()\n",
    "\n",
    "    indices = np.argsort(vectorizer.idf_)[::-1]\n",
    "    features = vectorizer.get_feature_names()\n",
    "    top_n = 10\n",
    "    top_features = [features[i] for i in indices[:top_n]]\n",
    "    \n",
    "    cluster_frequency_dict[i] = top_features\n",
    "\n",
    "cluster_frequency_df = pd.DataFrame(cluster_frequency_dict)\n",
    "print(cluster_frequency_df)\n",
    "\n",
    "FILE_NAME = \"output_tfidf.csv\"\n",
    "print(\"Exporting to csv file: %s\" %FILE_NAME)\n",
    "\n",
    "cluster_frequency_df.to_csv(FILE_NAME)\n",
    "\n",
    "print(\"Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Term Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cluster_frequency_dict = {}\n",
    "\n",
    "for i in range(num_clusters):\n",
    "\n",
    "    sub_frame = frame.loc[frame['cluster'] == i]\n",
    "    sub_data = sub_frame['sentence'].tolist()\n",
    "\n",
    "    vectorizer = CountVectorizer(stop_words='english', tokenizer=tokenize_and_stem)\n",
    "    count_matrix = vectorizer.fit_transform(sub_data)\n",
    "    \n",
    "    sum_words = count_matrix.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vectorizer.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    \n",
    "    top_n = 10\n",
    "\n",
    "    words_top_n_freq = [word_freq for word_freq, key in words_freq][:top_n]\n",
    "    cluster_frequency_dict[i] = words_top_n_freq\n",
    "    \n",
    "cluster_frequency_df = pd.DataFrame(cluster_frequency_dict)\n",
    "print(cluster_frequency_df)\n",
    "\n",
    "FILE_NAME = \"output_count.csv\"\n",
    "print(\"Exporting to csv file: %s\" %FILE_NAME)\n",
    "\n",
    "cluster_frequency_df.to_csv(FILE_NAME)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Restaurant : Top 100 words frequency\n",
    "#### Get Top 100 words in all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english',tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
    "# print(allReviewText)\n",
    "count_matrix = vectorizer.fit_transform(allReviewText)\n",
    "\n",
    "terms = vectorizer.get_feature_names() #Get all the features / vocab i think\n",
    "\n",
    "count_dataframe = pd.DataFrame(count_matrix.toarray(), columns = terms, index = allReviewBusinessId)\n",
    "# print(count_dataframe)\n",
    "\n",
    "\n",
    "# Get top n words\n",
    "sub_data = frame['sentence'].tolist()\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', tokenizer=tokenize_and_stem)\n",
    "count_matrix = vectorizer.fit_transform(sub_data)\n",
    "\n",
    "sum_words = count_matrix.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "top_n = 100\n",
    "\n",
    "words_top_n_freq = [word_freq for word_freq, key in words_freq][:top_n]\n",
    "print(words_top_n_freq)\n",
    "\n",
    "# filter dataframe to show only those with n words\n",
    "\n",
    "# count_dataframe[words_top_n_freq].groupby['index']\n",
    "\n",
    "# FILE_NAME = \"output_restaurant_to_topics.csv\"\n",
    "# print(\"Exporting to csv file: %s\" %FILE_NAME)\n",
    "\n",
    "# count_dataframe.to_csv(FILE_NAME)\n",
    "\n",
    "print(\"Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Restaurant Word Frequency Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dataframe_grouped = count_dataframe[words_top_n_freq].groupby(count_dataframe.index).sum()\n",
    "\n",
    "FILE_NAME = \"output_restaurant_to_topics.csv\"\n",
    "print(\"Exporting to csv file: %s\" %FILE_NAME)\n",
    "\n",
    "count_dataframe_grouped.to_csv(FILE_NAME)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Hierarchical Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the consine similiarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save dendrogram into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/\n",
    "\n",
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "\n",
    "linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
    "\n",
    "fig, ax = pl.subplots(figsize=(15, 30)) # set size\n",
    "ax = dendrogram(linkage_matrix, orientation=\"right\", labels=reviewSentenceList);\n",
    "\n",
    "pl.tick_params(\\\n",
    "    axis= 'x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    labelbottom='off')\n",
    "\n",
    "pl.tight_layout() #show plot with tight layout\n",
    "pl.savefig('ward_clusters.png', dpi=200) #save figure as ward_clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
